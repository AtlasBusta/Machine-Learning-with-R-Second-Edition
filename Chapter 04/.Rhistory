panel.text(0.365, 0.365, "Direction", cex=1)
panel.text(0.515, 0.515, "Grit",      cex=1)
panel.text(0.675, 0.675, "Rate",      cex=1)
panel.text(0.825, 0.825, "Speed",     cex=1)
trellis.unfocus()
#Step 5: Results Utilization
## Rearrange data so that factors and levels are in single columns.
n = length(df$strength[df$batch==1])
k = qt(.975,n-1)
group = rep(1:5,each=length(strength))
nstr = rep(newstrength,5)
level = c(m[,1],m[,2],m[,3],m[,4],m[,5])
dflong = data.frame(group,level,nstr)
gmn = aggregate(x=dflong$nstr,by=list(dflong$group,dflong$level),FUN="mean")
gsd = aggregate(x=dflong$nstr,by=list(dflong$group,dflong$level),FUN="sd")
cibar = k*gsd[3]/sqrt(n)
cgroup = rep(c("Speed","Rate","Grit","Direction","Batch"),2)
dfp = data.frame(cgroup,gmn,gsd[3],cibar)
names(dfp)=c("cgroup","group","level","tmean","std","cibar")
## Attach lattice library and generate main effects plot.
library(lattice)
par(mfrow=c(1,1))
xyplot(tmean~level|cgroup,data=dfp,layout=c(5,1),xlim=c(-2,2),
ylab="Transformed Strength",xlab="Factor Levels", type="b",
panel = function(x, y, ...){
panel.xyplot(x, y, ...)
panel.abline(h = mean(newstrength), lty = 2, col = 2)})
## Generate two types of 2-way interaction plots.
## 2-way interaction plots showing overall effects.
group2 = rep(1:10,each=length(newstrength))
nstr2 = rep(newstrength,10)
level2 = c(db,gd,gb,rg,rd,rb,sr,sg,ds,sb)
df2way = data.frame(group2,level2,nstr2)
gmn2 = aggregate(x=df2way$nstr2,by=list(df2way$group2,df2way$level2),FUN="mean")
gsd2 = aggregate(x=df2way$nstr2,by=list(df2way$group2,df2way$level2),FUN="sd")
cgr2 = rep(c("d*b","g*d","g*b","r*g","r*d","r*b","s*r","s*g","s*d","s*b"),2)
dfp2 = data.frame(cgr2,gmn2,gsd2[3])
names(dfp2)=c("cgroup","group","level","tmean","std")
# Generate plot.
sp = c(T,T,T,F, T,T,F,F, T,F,F,F, F,F,F,F)
strip.bg_custom = trellis.par.get("strip.background")
strip.bg_custom$col =c("#cce6ff","#ffe5cc","#ccffcc","#ccffff","#ffccff",
"#ffcccc","#ffffcc")
strip.sh_custom = strip.bg_custom
trellis.par.set("strip.background", strip.bg_custom)
trellis.par.set("strip.shingle", strip.sh_custom)
xyplot(tmean~level | group, data=dfp2, type="b", xlim=c(-2,2),
layout=c(4,4), skip=sp, col=c(4),
strip = function(..., style,factor.levels,strip.levels,strip.names)
strip.default(..., style = 1,factor.levels=cgr2,
strip.levels=c(F,T),strip.names=c(T,F)),
xlab="Factor Level", ylab="Transformed Strength",
panel = function(x, y, ...){
panel.xyplot(x, y, ...)
panel.abline(h = mean(newstrength), lty = 2, col = 2)})
## 2-way interaction plot showing means for all combinations of
## levels for the two factors.
## Compute means for plotting.
dfi = data.frame(s,r,g,d,b,newstrength)
mnsr = aggregate(x=dfi$newstrength,by=list(dfi$s,dfi$r),FUN="mean")
mnsg = aggregate(x=dfi$newstrength,by=list(dfi$s,dfi$g),FUN="mean")
mnsd = aggregate(x=dfi$newstrength,by=list(dfi$s,dfi$d),FUN="mean")
mnsb = aggregate(x=dfi$newstrength,by=list(dfi$s,dfi$b),FUN="mean")
mnrs = aggregate(x=dfi$newstrength,by=list(dfi$r,dfi$s),FUN="mean")
mnrg = aggregate(x=dfi$newstrength,by=list(dfi$r,dfi$g),FUN="mean")
mnrd = aggregate(x=dfi$newstrength,by=list(dfi$r,dfi$d),FUN="mean")
mnrb = aggregate(x=dfi$newstrength,by=list(dfi$r,dfi$b),FUN="mean")
mngs = aggregate(x=dfi$newstrength,by=list(dfi$g,dfi$s),FUN="mean")
mngr = aggregate(x=dfi$newstrength,by=list(dfi$g,dfi$r),FUN="mean")
mngd = aggregate(x=dfi$newstrength,by=list(dfi$g,dfi$d),FUN="mean")
mngb = aggregate(x=dfi$newstrength,by=list(dfi$g,dfi$b),FUN="mean")
mnds = aggregate(x=dfi$newstrength,by=list(dfi$d,dfi$s),FUN="mean")
mndr = aggregate(x=dfi$newstrength,by=list(dfi$d,dfi$r),FUN="mean")
mndg = aggregate(x=dfi$newstrength,by=list(dfi$d,dfi$g),FUN="mean")
mndb = aggregate(x=dfi$newstrength,by=list(dfi$d,dfi$b),FUN="mean")
mnbs = aggregate(x=dfi$newstrength,by=list(dfi$b,dfi$s),FUN="mean")
mnbr = aggregate(x=dfi$newstrength,by=list(dfi$b,dfi$r),FUN="mean")
mnbg = aggregate(x=dfi$newstrength,by=list(dfi$b,dfi$g),FUN="mean")
mnbd = aggregate(x=dfi$newstrength,by=list(dfi$b,dfi$d),FUN="mean")
xcol = rbind(mnbs,mnbr,mnbg,mnbd, mnds,mndr,mndg,mndb,
mngs,mngr,mngd,mngb, mnrs,mnrg,mnrd,mnrb, mnsr,mnsg,mnsd,mnsb)
gi = rep(c("b*s","b*r","b*g","b*d",
"d*s","d*r","d*g","d*b",
"g*s","g*r","g*d","g*b",
"r*s","r*g","r*d","r*b",
"s*r","s*g","s*d","s*b"),each=4)
dff = data.frame(gi,xcol)
## Generate the lattice plot.
sp = c(T,F,F,F,F, F,T,F,F,F, F,F,T,F,F, F,F,F,T,F, F,F,F,F,T)
xyplot(x ~ Group.1 | gi, data=dff, group=Group.2,
layout=c(5,5), skip=sp, xlim=c(-2,2),
ylab = "Transformed Strength", xlab = "Factor Level",
main = "Blue: low level, Pink: high level",
type=c("p","l"), pch=20, cex=1, col=c(4,6),
panel=function(x,y,...){panel.superpose(x,y,...)})
trellis.focus("toplevel") ## has coordinate system [0,1] x [0,1]
panel.text(0.200, 0.200, "Batch",     cex=1)
panel.text(0.365, 0.365, "Direction", cex=1)
panel.text(0.515, 0.515, "Grit",      cex=1)
panel.text(0.675, 0.675, "Rate",      cex=1)
panel.text(0.825, 0.825, "Speed",     cex=1)
trellis.unfocus()
setwd("~/GitHub/RStudio_datascience")
setwd("~/GitHub/Machine-Learning-with-R-Second-Edition/Chapter 04")
# read the sms data into the sms data frame
sms_raw <- read.csv("sms_spam.csv", stringsAsFactors = FALSE)
# examine the structure of the sms data
str(sms_raw)
# read the sms data into the sms data frame
sms_raw <- read.csv("sms_spam.csv", stringsAsFactors = FALSE)
View(sms_raw)
# examine the structure of the sms data
str(sms_raw)
# convert spam/ham to factor.
sms_raw$type <- factor(sms_raw$type)
View(sms_raw)
# examine the type variable more carefully
str(sms_raw$type)
table(sms_raw$type)
prop.table(sms_raw$type)
# build a corpus using the text mining (tm) package
library(tm)
sms_corpus <- VCorpus(VectorSource(sms_raw$text))
View(sms_corpus)
# examine the sms corpus
print(sms_corpus)
inspect(sms_corpus[1:2])
as.character(sms_corpus[[1]])
lapply(sms_corpus[1:2], as.character)
# clean up the corpus using tm_map()
sms_corpus_clean <- tm_map(sms_corpus, content_transformer(tolower))
View(sms_corpus_clean)
# show the difference between sms_corpus and corpus_clean
as.character(sms_corpus[[1]])
as.character(sms_corpus_clean[[1]])
sms_corpus_clean <- tm_map(sms_corpus_clean, removeNumbers) # remove numbers
sms_corpus_clean <- tm_map(sms_corpus_clean, removeWords, stopwords()) # remove stop words
sms_corpus_clean <- tm_map(sms_corpus_clean, removePunctuation) # remove punctuation
as.character(sms_corpus_clean[[1]])
# show the difference between sms_corpus and corpus_clean
as.character(sms_corpus[[1]])
as.character(sms_corpus_clean[[1]])
# tip: create a custom function to replace (rather than remove) punctuation
removePunctuation("hello...world")
replacePunctuation <- function(x) { gsub("[[:punct:]]+", " ", x) }
replacePunctuation("hello...world")
# illustration of word stemming
library(SnowballC)
wordStem(c("learn", "learned", "learning", "learns"))
sms_corpus_clean <- tm_map(sms_corpus_clean, stemDocument)
sms_corpus_clean <- tm_map(sms_corpus_clean, stripWhitespace) # eliminate unneeded whitespace
# examine the final clean corpus
lapply(sms_corpus[1:3], as.character)
lapply(sms_corpus_clean[1:3], as.character)
# create a document-term sparse matrix
sms_dtm <- DocumentTermMatrix(sms_corpus_clean)
View(sms_dtm)
# alternative solution: create a document-term sparse matrix directly from the SMS corpus
sms_dtm2 <- DocumentTermMatrix(sms_corpus, control = list(
tolower = TRUE,
removeNumbers = TRUE,
stopwords = TRUE,
removePunctuation = TRUE,
stemming = TRUE
))
# alternative solution: using custom stop words function ensures identical result
sms_dtm3 <- DocumentTermMatrix(sms_corpus, control = list(
tolower = TRUE,
removeNumbers = TRUE,
stopwords = function(x) { removeWords(x, stopwords()) },
removePunctuation = TRUE,
stemming = TRUE
))
# compare the result
sms_dtm
sms_dtm2
sms_dtm3
# creating training and test datasets
sms_dtm_train <- sms_dtm[1:4169, ]
sms_dtm_test  <- sms_dtm[4170:5559, ]
# also save the labels
sms_train_labels <- sms_raw[1:4169, ]$type
sms_test_labels  <- sms_raw[4170:5559, ]$type
View(sms_dtm_test)
# check that the proportion of spam is similar
prop.table(table(sms_train_labels))
prop.table(table(sms_test_labels))
# word cloud visualization
library(wordcloud)
wordcloud(sms_corpus_clean, min.freq = 50, random.order = FALSE)
# subset the training data into spam and ham groups
spam <- subset(sms_raw, type == "spam")
ham  <- subset(sms_raw, type == "ham")
wordcloud(spam$text, max.words = 40, scale = c(3, 0.5))
wordcloud(ham$text, max.words = 40, scale = c(3, 0.5))
# indicator features for frequent words
findFreqTerms(sms_dtm_train, 5)
# save frequently-appearing terms to a character vector
sms_freq_words <- findFreqTerms(sms_dtm_train, 5)
str(sms_freq_words)
# create DTMs with only the frequent terms
sms_dtm_freq_train <- sms_dtm_train[ , sms_freq_words]
sms_dtm_freq_test <- sms_dtm_test[ , sms_freq_words]
# convert counts to a factor
convert_counts <- function(x) {
x <- ifelse(x > 0, "Yes", "No")
}
View(sms_dtm_freq_test)
View(sms_dtm_freq_train)
# apply() convert_counts() to columns of train/test data
sms_train <- apply(sms_dtm_freq_train, MARGIN = 2, convert_counts)
sms_test  <- apply(sms_dtm_freq_test, MARGIN = 2, convert_counts)
View(sms_test)
View(sms_dtm_freq_train)
View(sms_test)
View(sms_train)
# save frequently-appearing terms to a character vector
sms_freq_words <- findFreqTerms(sms_dtm_train, 5)
## Step 3: Training a model on the data ----
library(e1071)
sms_classifier <- naiveBayes(sms_train, sms_train_labels)
## Step 4: Evaluating model performance ----
sms_test_pred <- predict(sms_classifier, sms_test)
library(gmodels)
CrossTable(sms_test_pred, sms_test_labels,
prop.chisq = FALSE, prop.t = FALSE, prop.r = FALSE,
dnn = c('predicted', 'actual'))
## Step 5: Improving model performance ----
sms_classifier2 <- naiveBayes(sms_train, sms_train_labels, laplace = 1)
sms_test_pred2 <- predict(sms_classifier2, sms_test)
CrossTable(sms_test_pred2, sms_test_labels,
prop.chisq = FALSE, prop.t = FALSE, prop.r = FALSE,
dnn = c('predicted', 'actual'))
## Step 5: Improving model performance ----
sms_classifier2 <- naiveBayes(sms_train, sms_train_labels, laplace = 1)
sms_test_pred2 <- predict(sms_classifier2, sms_test)
CrossTable(sms_test_pred2, sms_test_labels,
prop.chisq = FALSE, prop.t = FALSE, prop.r = FALSE,
dnn = c('predicted', 'actual'))
sms_data_clean <- rbind(sms_test,sms_test)
sms_data_clean <- rbind(sms_train,sms_test)
sms_features_clean <- rbind(sms_train,sms_test)
rm(sms_data_clean)
sms_labels_clean <- c(sms_train_labels, sms_test_labels)
dim(sms_labels_clean)
length(sms_labels_clean)
# Load necessary library
library(caTools)
# Function to split dataset
split_dataset <- function(features, labels, split_ratio) {
set.seed(123) # for reproducibility
split_index <- sample.split(labels, SplitRatio = split_ratio)
train_features <- features[split_index, ]
test_features <- features[!split_index, ]
train_labels <- labels[split_index]
test_labels <- labels[!split_index]
return(list("train_features" = train_features,
"test_features" = test_features,
"train_labels" = train_labels,
"test_labels" = test_labels))
}
# Combine datasets
combined_features <- rbind(sms_train, sms_test)
combined_labels <- c(sms_train_labels, sms_test_labels)
length(combined_labels)
# Split the dataset into different ratios
splits <- list("50:50" = 0.5, "70:30" = 0.7, "75:25" = 0.75, "80:20" = 0.8, "90:10" = 0.9)
split_datasets <- lapply(splits, function(split_ratio) {
split_dataset(combined_features, combined_labels, split_ratio)
})
View(split_datasets[["70:30"]]$train_features)
## Step 3: Training a model on the data ----
sms_classifier_50_50 <- naiveBayes(split_datasets[["50:50"]]$train_features, split_datasets[["50:50"]]$train_labels)
## Step 4: Evaluating model performance ----
sms_test_pred_50_50 <- predict(sms_classifier_50_50, split_datasets[["50:50"]]$test_features)
CrossTable(sms_test_pred_50_50, split_datasets[["50:50"]]$test_labels,
prop.chisq = FALSE, prop.t = FALSE, prop.r = FALSE,
dnn = c('predicted', 'actual'))
prop.table(table(split_datasets[["50:50"]]$train_labels,split_datasets[["50:50"]]$test_labels))
prop.table(table(split_datasets[["50:50"]]$train_labels))
prop.table(table(split_datasets[["50:50"]]$test_labels))
# Function to calculate and print proportion tables for train and test labels
calculate_proportions <- function(split_datasets) {
for (split in names(split_datasets)) {
cat("Proportions for", split, "split:\n")
cat("Train Labels:\n")
print(prop.table(table(split_datasets[[split]]$train_labels)))
cat("Test Labels:\n")
print(prop.table(table(split_datasets[[split]]$test_labels)))
cat("\n")
}
}
# Calculate and print proportions for all splits
calculate_proportions(split_datasets)
View(sms_dtm3)
View(sms_test)
View(sms_train)
sms_classifier_50_50_2 <- naiveBayes(split_datasets[["50:50"]]$train_features, split_datasets[["50:50"]]$train_labels, laplace = 1)
sms_test_pred_50_50_2 <- predict(sms_classifier_50_50_2, split_datasets[["50:50"]]$test_features)
CrossTable(sms_test_pred_50_50_2, split_datasets[["50:50"]]$test_labels,
prop.chisq = FALSE, prop.t = FALSE, prop.r = FALSE,
dnn = c('predicted', 'actual'))
sms_classifier <- naiveBayes(split_datasets[["50:50"]]$train_features, split_datasets[["50:50"]]$train_labels)
## Evaluate model performance
sms_test_pred <- predict(sms_classifier, split_datasets[["50:50"]]$test_features)
CrossTable(sms_test_pred, split_datasets[["50:50"]]$test_labels,
prop.chisq = FALSE, prop.t = FALSE, prop.r = FALSE,
dnn = c('predicted', 'actual'))
## Improving model performance Laplace 1
sms_classifier2 <- naiveBayes(split_datasets[["50:50"]]$train_features, split_datasets[["50:50"]]$train_labels, laplace = 1)
sms_test_pred2 <- predict(sms_classifier2, split_datasets[["50:50"]]$test_features)
CrossTable(sms_test_pred2, split_datasets[["50:50"]]$test_labels,
prop.chisq = FALSE, prop.t = FALSE, prop.r = FALSE,
dnn = c('predicted', 'actual'))
# Function to train, predict, and print cross table
train_predict_print <- function(split_datasets) {
results <- list() # To store results
for (split in names(split_datasets)) {
cat("Training and evaluating for split:", split, "\n")
# Train the model
model <- naiveBayes(split_datasets[[split]]$train_features, split_datasets[[split]]$train_labels)
# Make predictions
predictions <- predict(model, split_datasets[[split]]$test_features)
# Print cross table
cross_tab <- CrossTable(predictions, split_datasets[[split]]$test_labels,
prop.chisq = FALSE, prop.t = FALSE, prop.r = FALSE,
dnn = c('predicted', 'actual'))
# Store results
results[[split]] <- list("model" = model, "predictions" = predictions, "cross_tab" = cross_tab)
cat("\n")
}
return(results)
}
# Use the function
model_results <- train_predict_print(split_datasets)
gc()
##### Chapter 4: Classification using Naive Bayes --------------------
## Example: Filtering spam SMS messages ----
## Step 2: Exploring and preparing the data ----
# read the sms data into the sms data frame
sms_raw <- read.csv("sms_spam.csv", stringsAsFactors = FALSE)
# examine the structure of the sms data
str(sms_raw)
# convert spam/ham to factor.
sms_raw$type <- factor(sms_raw$type)
# examine the type variable more carefully
str(sms_raw$type)
table(sms_raw$type)
# build a corpus using the text mining (tm) package
library(tm)
sms_corpus <- VCorpus(VectorSource(sms_raw$text))
# examine the sms corpus
print(sms_corpus)
inspect(sms_corpus[1:2])
as.character(sms_corpus[[1]])
lapply(sms_corpus[1:2], as.character)
# clean up the corpus using tm_map()
sms_corpus_clean <- tm_map(sms_corpus, content_transformer(tolower))
# show the difference between sms_corpus and corpus_clean
as.character(sms_corpus[[1]])
as.character(sms_corpus_clean[[1]])
sms_corpus_clean <- tm_map(sms_corpus_clean, removeNumbers) # remove numbers
sms_corpus_clean <- tm_map(sms_corpus_clean, removeWords, stopwords()) # remove stop words
sms_corpus_clean <- tm_map(sms_corpus_clean, removePunctuation) # remove punctuation
# tip: create a custom function to replace (rather than remove) punctuation
removePunctuation("hello...world")
replacePunctuation <- function(x) { gsub("[[:punct:]]+", " ", x) }
replacePunctuation("hello...world")
# illustration of word stemming
library(SnowballC)
wordStem(c("learn", "learned", "learning", "learns"))
sms_corpus_clean <- tm_map(sms_corpus_clean, stemDocument)
sms_corpus_clean <- tm_map(sms_corpus_clean, stripWhitespace) # eliminate unneeded whitespace
# examine the final clean corpus
lapply(sms_corpus[1:3], as.character)
lapply(sms_corpus_clean[1:3], as.character)
# create a document-term sparse matrix
sms_dtm <- DocumentTermMatrix(sms_corpus_clean)
# alternative solution: create a document-term sparse matrix directly from the SMS corpus
sms_dtm2 <- DocumentTermMatrix(sms_corpus, control = list(
tolower = TRUE,
removeNumbers = TRUE,
stopwords = TRUE,
removePunctuation = TRUE,
stemming = TRUE
))
# alternative solution: using custom stop words function ensures identical result
sms_dtm3 <- DocumentTermMatrix(sms_corpus, control = list(
tolower = TRUE,
removeNumbers = TRUE,
stopwords = function(x) { removeWords(x, stopwords()) },
removePunctuation = TRUE,
stemming = TRUE
))
# compare the result
sms_dtm
sms_dtm2
sms_dtm3
# creating training and test datasets
sms_dtm_train <- sms_dtm[1:4169, ]
sms_dtm_test  <- sms_dtm[4170:5559, ]
# also save the labels
sms_train_labels <- sms_raw[1:4169, ]$type
sms_test_labels  <- sms_raw[4170:5559, ]$type
# check that the proportion of spam is similar
prop.table(table(sms_train_labels))
prop.table(table(sms_test_labels))
# word cloud visualization
library(wordcloud)
wordcloud(sms_corpus_clean, min.freq = 50, random.order = FALSE)
# subset the training data into spam and ham groups
spam <- subset(sms_raw, type == "spam")
ham  <- subset(sms_raw, type == "ham")
wordcloud(spam$text, max.words = 40, scale = c(3, 0.5))
wordcloud(ham$text, max.words = 40, scale = c(3, 0.5))
sms_dtm_freq_train <- removeSparseTerms(sms_dtm_train, 0.999)
sms_dtm_freq_train
# indicator features for frequent words
findFreqTerms(sms_dtm_train, 5)
# save frequently-appearing terms to a character vector
sms_freq_words <- findFreqTerms(sms_dtm_train, 5)
str(sms_freq_words)
# create DTMs with only the frequent terms
sms_dtm_freq_train <- sms_dtm_train[ , sms_freq_words]
sms_dtm_freq_test <- sms_dtm_test[ , sms_freq_words]
# convert counts to a factor
convert_counts <- function(x) {
x <- ifelse(x > 0, "Yes", "No")
}
# apply() convert_counts() to columns of train/test data
sms_train <- apply(sms_dtm_freq_train, MARGIN = 2, convert_counts)
sms_test  <- apply(sms_dtm_freq_test, MARGIN = 2, convert_counts)
## Step 3: Training a model on the data ----
library(e1071)
sms_classifier <- naiveBayes(sms_train, sms_train_labels)
## Step 4: Evaluating model performance ----
sms_test_pred <- predict(sms_classifier, sms_test)
library(gmodels)
CrossTable(sms_test_pred, sms_test_labels,
prop.chisq = FALSE, prop.t = FALSE, prop.r = FALSE,
dnn = c('predicted', 'actual'))
## Step 5: Improving model performance ----
sms_classifier2 <- naiveBayes(sms_train, sms_train_labels, laplace = 1)
sms_test_pred2 <- predict(sms_classifier2, sms_test)
CrossTable(sms_test_pred2, sms_test_labels,
prop.chisq = FALSE, prop.t = FALSE, prop.r = FALSE,
dnn = c('predicted', 'actual'))
# Try new train and test splits
# Load necessary library
library(caTools)
# Function to split dataset
split_dataset <- function(features, labels, split_ratio) {
set.seed(123) # for reproducibility
split_index <- sample.split(labels, SplitRatio = split_ratio)
train_features <- features[split_index, ]
test_features <- features[!split_index, ]
train_labels <- labels[split_index]
test_labels <- labels[!split_index]
return(list("train_features" = train_features,
"test_features" = test_features,
"train_labels" = train_labels,
"test_labels" = test_labels))
}
# Combine datasets
combined_features <- rbind(sms_train, sms_test)
combined_labels <- c(sms_train_labels, sms_test_labels)
# Split the dataset into different ratios
splits <- list("50:50" = 0.5, "70:30" = 0.7, "75:25" = 0.75, "80:20" = 0.8, "90:10" = 0.9)
split_datasets <- lapply(splits, function(split_ratio) {
split_dataset(combined_features, combined_labels, split_ratio)
})
# Function to calculate and print proportion tables for train and test labels
calculate_proportions <- function(split_datasets) {
for (split in names(split_datasets)) {
cat("Proportions for", split, "split:\n")
cat("Train Labels:\n")
print(prop.table(table(split_datasets[[split]]$train_labels)))
cat("Test Labels:\n")
print(prop.table(table(split_datasets[[split]]$test_labels)))
cat("\n")
}
}
# Calculate and print proportions for all splits
calculate_proportions(split_datasets)
# Function to train, predict, and print cross table
train_predict_print <- function(split_datasets) {
results <- list() # To store results
for (split in names(split_datasets)) {
cat("Training and evaluating for split:", split, "\n")
# Train the model
model <- naiveBayes(split_datasets[[split]]$train_features, split_datasets[[split]]$train_labels)
# Make predictions
predictions <- predict(model, split_datasets[[split]]$test_features)
# Print cross table
cross_tab <- CrossTable(predictions, split_datasets[[split]]$test_labels,
prop.chisq = FALSE, prop.t = FALSE, prop.r = FALSE,
dnn = c('predicted', 'actual'))
# Store results
results[[split]] <- list("model" = model, "predictions" = predictions, "cross_tab" = cross_tab)
cat("\n")
}
return(results)
}
# Use the function
model_results <- train_predict_print(split_datasets)
View(splits)
View(train_predict_print)
View(split_dataset)
?lapply
View(sms_train)
View(sms_corpus)
gc()
